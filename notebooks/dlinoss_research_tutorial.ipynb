{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e2c71b44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook CWD set to repository root: /home/rustuser/projects/rust/active/dlinossrustcandle/notebooks\n",
      "Toolchain: stable | Device: Cpu | CWD: /home/rustuser/projects/rust/active/dlinossrustcandle/notebooks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Toolchain: stable\n"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ":toolchain stable\n",
    ":dep dlinoss-notebooks = { path = \".\", features = [\"fft\"] }\n",
    "//! Doc: D-LinOSS research tutorial — environment and I/O init\n",
    "//! Tags: dlinoss, research, evcxr, dlinoss-notebooks, cell-1\n",
    "// Purpose: Standardize kernel/toolchain and working directory for reproducible notebook runs.\n",
    "// Why: Consistent CWD ensures image/data paths work regardless of how the notebook is launched.\n",
    "// Safety: This cell performs file-system setup only; no model parameters are created.\n",
    "// Performance: Negligible; directory creation is idempotent.\n",
    "// Repro: Keep this cell as the first executable cell in the notebook.\n",
    "// Feature flags: Not required here; handled later in dependency cells.\n",
    "// GPU note: Device selection defaults to CPU; change later if GPU support is enabled.\n",
    "// Logging: Prints toolchain, device, and CWD for quick diagnostics.\n",
    "// References: See dlinoss-notebooks (re-export) for utilities.\n",
    "// Doc-scan: These header comments aid later automated documentation scans.\n",
    "use dlinoss_notebooks::*;\n",
    "use std::fs;\n",
    "let device: Device = Device::Cpu;\n",
    "// Normalize working directory for file I/O (images, datasets).\n",
    "set_notebook_cwd().expect(\"failed to set notebook cwd\");\n",
    "fs::create_dir_all(\"images_store\").ok();\n",
    "println!(\"Toolchain: stable | Device: {:?} | CWD: {}\", device, std::env::current_dir().unwrap().display());"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc7ee233",
   "metadata": {},
   "source": [
    "# D-LinOSS for SSM researchers: a practical notebook\n",
    "\n",
    "This tutorial shows how to use the D-LinOSS (Damped Linear Oscillatory State-Space) layer in Candle for research-grade signal studies and rapid experiments.\n",
    "\n",
    "It’s written from an SSM/deep-learning research angle, not as a Rust API tour. You’ll:\n",
    "- Build a D-LinOSS layer on Candle tensors (CPU).\n",
    "- Generate canonical test inputs (impulse, step, sine/chirp).\n",
    "- Run the layer and inspect responses (stability, shapes, quick metrics).\n",
    "- See how to extend to FFT analysis (optional).\n",
    "\n",
    "Notation (continuous-time SSM): \\( \\ot{x} = A x + B u,\\ y = C x + D u \\) with damped 2×2 oscillatory blocks for poles \\(-\\alpha \\pm i\\omega\\).\n",
    "Discrete-time stability comes from the exact block exponential (\\(\\rho(A_d)=e^{-\\alpha\\Delta t}<1\\)))."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f20f5f",
   "metadata": {},
   "source": [
    "## 1) Kernel and dependencies (evcxr)\n",
    "If you run this in a Rust Jupyter kernel (evcxr), use \n",
    "\n",
    "- The notebook lives in `dlinossrustcandle/notebooks/`.\n",
    "- Single-dependency rule: use only `:dep dlinoss-notebooks = { path = \".\" }`.\n",
    "  - This glue crate re-exports Candle notebook utilities and the D-LinOSS API (and optional FFT helper), so no other `:dep` entries are needed.\n",
    "- Optional: build the glue crate with `features = [\"fft\"]` to enable FFT helper usage in this notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e40dd22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ dlinoss-notebooks imports ready\n"
     ]
    }
   ],
   "source": [
    "//! Doc: D-LinOSS research tutorial — base imports via dlinoss-notebooks glue\n",
    "//! Tags: dlinoss-notebooks, imports, types, cell-3\n",
    "// Purpose: Prefer a single dependency `dlinoss-notebooks` for notebooks.\n",
    "// Why: It re-exports common types (Tensor, Device, DType, Result) and the D-LinOSS API.\n",
    "// Safety: No side effects; imports only.\n",
    "// Performance: None; compile-time only.\n",
    "// Repro: Keeps notebooks consistent across the repo.\n",
    "// Feature flags: Managed at crate build time; not needed here.\n",
    "// GPU note: Device can be switched later if GPU is enabled in the build.\n",
    "// Doc-scan: Header comments help later documentation tooling.\n",
    "use dlinoss_notebooks::{Tensor, Device, DType, Result, DLinOssLayer, DLinOssLayerConfig};\n",
    "// Optional helper (exists even when fft feature is off; returns empty vec then)\n",
    "use dlinoss_notebooks::rfft_magnitude;\n",
    "\n",
    "println!(\"✓ dlinoss-notebooks imports ready\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31dd5e10",
   "metadata": {},
   "source": [
    "## 2) Construct a D-LinOSS layer\n",
    "Choose state/input/output dims and sampling step. Default dtype is f32, device CPU.\n",
    "We’ll also set a stable, reasonably excited parameterization for exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4a8c5992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer: state_dim=32, delta_t=0.005 s\n"
     ]
    }
   ],
   "source": [
    "//! Doc: Build a D-LinOSS layer with stable-ish initialization\n",
    "//! Tags: dlinoss, layer, config, stability, cell-6\n",
    "// Purpose: Construct a DLinOssLayer and set parameters for bounded dynamics.\n",
    "// Why: Stable initialization avoids exploding responses over long horizons.\n",
    "// Shapes: state_dim=m, input_dim=p, output_dim=q; dtype f32 on CPU by default.\n",
    "// Safety: Pure tensor ops; no unsafe or file I/O here.\n",
    "// Parameters: delta_t controls discretization step; tune for your sampling rate.\n",
    "// Research: Adjust `g_const`, scaling of `b`, or layer size to explore response behavior.\n",
    "// Extensibility: Make parameters trainable later during model fitting.\n",
    "// Diagnostics: Prints state_dim and delta_t upon construction.\n",
    "// Doc-scan: Header comments facilitate documentation extraction for research notes.\n",
    "fn build_layer() -> Result<DLinOssLayer> {\n",
    "    let device = Device::Cpu;\n",
    "    let cfg = DLinOssLayerConfig {\n",
    "        state_dim: 32,\n",
    "        input_dim: 1,\n",
    "        output_dim: 1,\n",
    "        delta_t: 5e-3,\n",
    "        dtype: DType::F32,\n",
    "    };\n",
    "    let mut layer = DLinOssLayer::new(cfg, &device)?;\n",
    "    // Simple stable-ish init (damped band)\n",
    "    let device = layer.a.device().clone();\n",
    "    let m: usize = {\n",
    "        let d = layer.a.dims();\n",
    "        assert_eq!(d.len(), 1);\n",
    "        d[0]\n",
    "    };\n",
    "    let g_const = 0.2f32;\n",
    "    layer.g = Tensor::full(g_const, (m,), &device)?.to_dtype(DType::F32)?;\n",
    "    let dt = layer.delta_t;\n",
    "    let s = layer.g.affine(dt, 1.0)?;          // 1 + dt * G\n",
    "    let sqrt_s = s.sqrt()?;                     // sqrt(1 + dt*G)\n",
    "    let two_plus_dtg = s.affine(1.0, 1.0)?;     // 2 + dt * G\n",
    "    let two_sqrt = sqrt_s.affine(2.0, 0.0)?;    // 2 * sqrt(...)\n",
    "    let inv_dt2 = 1.0 / (dt * dt);\n",
    "    let a_low = two_plus_dtg.sub(&two_sqrt)?.affine(inv_dt2, 0.0)?;\n",
    "    let a_high = two_plus_dtg.add(&two_sqrt)?.affine(inv_dt2, 0.0)?;\n",
    "    layer.a = (&a_low + &a_high)?.affine(0.5, 0.0)?; // midpoint\n",
    "    layer.b = layer.b.affine(0.12, 0.0)?;            // modest drive\n",
    "    Ok(layer)\n",
    "}\n",
    "\n",
    "let layer: DLinOssLayer = build_layer().expect(\"build_layer failed\");\n",
    "let m: usize = layer.a.dims()[0];\n",
    "println!(\"layer: state_dim={}, delta_t={} s\", m, layer.delta_t);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e53e27",
   "metadata": {},
   "source": [
    "## 3) Generate canonical inputs (impulse, step, sine, chirp)\n",
    "Inputs are shaped [B, T, In]. Here we use B=1, In=1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf0b0875",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SignalGen imported: methods available -> impulse, step, sine, chirp\n"
     ]
    }
   ],
   "source": [
    "//! Doc: Signal generation utilities imported from dlinoss-notebooks\n",
    "//! Tags: signals, test-inputs, impulse, step, sine, chirp, shared-utils, cell-generators\n",
    "// Purpose: Use the shared SignalGen from the glue crate so notebooks don't duplicate code.\n",
    "// Why: Centralizing common helpers reduces drift and ensures consistency.\n",
    "// Approach: Import and rely on dlinoss-notebooks::SignalGen methods.\n",
    "// Performance: Same as before; simple vector math and Tensor creation.\n",
    "// Research: Impulse tests transient response; sine tests frequency response; chirp tests bandwidth.\n",
    "// Extensibility: Add more signal types in the glue crate once and reuse everywhere.\n",
    "// Doc-scan: Header documentation aids automated scanning tools.\n",
    "use dlinoss_notebooks::SignalGen;\n",
    "\n",
    "println!(\"SignalGen imported: methods available -> impulse, step, sine, chirp\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e0c95b",
   "metadata": {},
   "source": [
    "## 4) Run the layer and inspect outputs\n",
    "We run impulse and step responses, plus a short sine. We’ll print shape summaries and quick metrics (RMS).\n",
    "\n",
    "Fun fact: if this cell eats too many tensors, it gets gassy and blows up the font size. Don’t worry—we’ve put it on a strict diet of stable params and small T."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "015c42a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward processing results:\n",
      "  Impulse response RMS: 0.0000\n",
      "  Step response RMS:    0.0000\n",
      "  Sine response RMS:    0.0000\n",
      "  Impulse first 5: [1.9519399e-5, 5.829172e-12, -1.9499888e-5, -1.1515965e-11, 1.9480396e-5]\n",
      "  Step first 5: [9.759699e-6, 9.759702e-6, 9.758908e-9, 9.752641e-9, 9.7499515e-6]\n",
      "  Sine first 5: [0.0, 1.2256332e-6, 2.44643e-6, 2.4331634e-6, 2.4102942e-6]\n",
      "  Impulse response RMS: 0.0000\n",
      "  Step response RMS:    0.0000\n",
      "  Sine response RMS:    0.0000\n",
      "  Impulse first 5: [1.9519399e-5, 5.829172e-12, -1.9499888e-5, -1.1515965e-11, 1.9480396e-5]\n",
      "  Step first 5: [9.759699e-6, 9.759702e-6, 9.758908e-9, 9.752641e-9, 9.7499515e-6]\n",
      "  Sine first 5: [0.0, 1.2256332e-6, 2.44643e-6, 2.4331634e-6, 2.4102942e-6]\n"
     ]
    }
   ],
   "source": [
    "//! Doc: Forward processing with D-LinOSS layer and signal analysis\n",
    "//! Tags: forward-pass, rms-metrics, signal-processing, layer-response, cell-analysis\n",
    "// Purpose: Run various test signals through D-LinOSS layer and compute basic metrics.\n",
    "// Why: Characterize layer behavior across different input types (transients, steady-state, periodic).\n",
    "// Approach: Use a Result-returning closure to keep `?` scoped and avoid REPL never-type issues.\n",
    "// Performance: Sequential processing of small test signals; efficient for characterization.\n",
    "// Research: RMS values indicate energy transfer; sample previews show response dynamics.\n",
    "// Extensibility: Could add frequency analysis, stability metrics, or multi-channel processing.\n",
    "// Signal generation: Use shared SignalGen methods.\n",
    "\n",
    "let result: Result<(Tensor, f32, f32, f32)> = (|| -> Result<(Tensor, f32, f32, f32)> {\n",
    "    let mut layer: DLinOssLayer = build_layer()?;\n",
    "    let t: usize = 64usize;\n",
    "    let dt: f32 = layer.delta_t as f32;\n",
    "\n",
    "    // Test signals using SignalGen\n",
    "    let x_imp: Tensor = SignalGen::impulse(t)?;\n",
    "    let x_step: Tensor = SignalGen::step(t, 0.5)?;\n",
    "    let x_sine: Tensor = SignalGen::sine(t, 2.0, dt)?;\n",
    "\n",
    "    // Forward passes\n",
    "    let y_imp: Tensor = layer.forward(&x_imp, None)?;\n",
    "    let y_step: Tensor = layer.forward(&x_step, None)?;\n",
    "    let y_sine: Tensor = layer.forward(&x_sine, None)?;\n",
    "\n",
    "    // Store y_sine for FFT analysis in next cells\n",
    "    let y_sine_flat: Tensor = y_sine.squeeze(0)?.squeeze(1)?;\n",
    "\n",
    "    // Compute RMS metrics directly\n",
    "    let y_imp_flat: Vec<f32> = y_imp.squeeze(0)?.squeeze(1)?.to_vec1::<f32>()?;\n",
    "    let rms_imp: f32 = {\n",
    "        let sum_sq: f32 = y_imp_flat.iter().map(|x| x * x).sum();\n",
    "        (sum_sq / y_imp_flat.len() as f32).sqrt()\n",
    "    };\n",
    "\n",
    "    let y_step_flat: Vec<f32> = y_step.squeeze(0)?.squeeze(1)?.to_vec1::<f32>()?;\n",
    "    let rms_step: f32 = {\n",
    "        let sum_sq: f32 = y_step_flat.iter().map(|x| x * x).sum();\n",
    "        (sum_sq / y_step_flat.len() as f32).sqrt()\n",
    "    };\n",
    "\n",
    "    let y_sine_vec: Vec<f32> = y_sine_flat.to_vec1::<f32>()?;\n",
    "    let rms_sine: f32 = {\n",
    "        let sum_sq: f32 = y_sine_vec.iter().map(|x| x * x).sum();\n",
    "        (sum_sq / y_sine_vec.len() as f32).sqrt()\n",
    "    };\n",
    "\n",
    "    println!(\"Forward processing results:\");\n",
    "    println!(\"  Impulse response RMS: {:.4}\", rms_imp);\n",
    "    println!(\"  Step response RMS:    {:.4}\", rms_step);\n",
    "    println!(\"  Sine response RMS:    {:.4}\", rms_sine);\n",
    "\n",
    "    // Preview first few samples\n",
    "    println!(\"  Impulse first 5: {:?}\", &y_imp_flat[0..5.min(y_imp_flat.len())]);\n",
    "    println!(\"  Step first 5: {:?}\", &y_step_flat[0..5.min(y_step_flat.len())]);\n",
    "    println!(\"  Sine first 5: {:?}\", &y_sine_vec[0..5.min(y_sine_vec.len())]);\n",
    "\n",
    "    Ok((y_sine_flat, rms_imp, rms_step, rms_sine))\n",
    "})();\n",
    "\n",
    "let (y_sine_flat, rms_imp, rms_step, rms_sine): (Tensor, f32, f32, f32) = result.expect(\"forward processing failed\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b103e0",
   "metadata": {},
   "source": [
    "### On stability\n",
    "We use a stable parametrization (damped oscillatory blocks) so long-horizon responses remain bounded.\n",
    "A simple check is that RMS doesn’t blow up as `T` grows (for bounded inputs). More formal checks can compare \"before/after\" energy or spectral radius in the discrete domain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85fc0167",
   "metadata": {},
   "source": [
    "## 5) Optional: FFT-based analysis\n",
    "If you enabled the `fft` feature in the :dep section, you can take short windows of the output and inspect frequency content.\n",
    "Below is a minimal real-FFT magnitude sketch. If FFT is not enabled, it prints a note."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a353c700",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DEBUG] cpu_fft: n = 64, batch_size = 1, stride = 1, dims = [64], input.len() = 64\n",
      "FFT bins: 33 | Sample rate: 200.0 Hz | Freq resolution: 3.12 Hz/bin\n",
      "Magnitude spectrum (first 8 bins): [3.1389165e-5, 2.7830505e-5, 6.7367864e-6, 3.884639e-6, 2.766933e-6, 2.1649766e-6, 1.7866902e-6, 1.5264236e-6]\n",
      "Peak at bin 0 (0.0 Hz) with magnitude 0.0000\n",
      "FFT bins: 33 | Sample rate: 200.0 Hz | Freq resolution: 3.12 Hz/bin\n",
      "Magnitude spectrum (first 8 bins): [3.1389165e-5, 2.7830505e-5, 6.7367864e-6, 3.884639e-6, 2.766933e-6, 2.1649766e-6, 1.7866902e-6, 1.5264236e-6]\n",
      "Peak at bin 0 (0.0 Hz) with magnitude 0.0000\n"
     ]
    }
   ],
   "source": [
    "//! Doc: Real FFT magnitude spectrum analysis using dlinoss-notebooks\n",
    "//! Tags: fft, spectral, magnitude, dlinoss-notebooks, cell-13\n",
    "// Purpose: Compute spectral magnitudes from the output window using the helper function.\n",
    "// Why: Frequency-domain views complement time-domain responses for oscillatory systems.\n",
    "// Requirements: FFT feature enabled at crate build time; uses dlinoss-notebooks::rfft_magnitude.\n",
    "// Safety: Pure numerical; tensor conversions are validated.\n",
    "// Performance: FFT cost depends on window size; keep small for interactivity.\n",
    "// Research: Identify resonance/damping patterns across frequency bins.\n",
    "// Extensibility: Plot magnitude spectrum or compare across parameter sweeps.\n",
    "// Feature-gated: This works when crate is built with --features fft (falls back to empty vec otherwise).\n",
    "\n",
    "let fft_res: Result<()> = (|| -> Result<()> {\n",
    "    let y = y_sine_flat.to_vec1::<f32>()?;\n",
    "    let win = 256.min(y.len());\n",
    "    let signal_window = &y[y.len()-win..];\n",
    "\n",
    "    let magnitudes = rfft_magnitude(signal_window)?;\n",
    "\n",
    "    if magnitudes.is_empty() {\n",
    "        println!(\"FFT not enabled; build with --features fft for spectral analysis\");\n",
    "    } else {\n",
    "        // Rebuild layer config just to get delta_t (sample rate)\n",
    "        let tmp_layer = build_layer()?;\n",
    "        let sample_rate = 1.0 / tmp_layer.delta_t as f32;  // Hz\n",
    "        let freq_resolution = sample_rate / (win as f32);  // Hz per bin\n",
    "        println!(\"FFT bins: {} | Sample rate: {:.1} Hz | Freq resolution: {:.2} Hz/bin\", \n",
    "                 magnitudes.len(), sample_rate, freq_resolution);\n",
    "        \n",
    "        // Show first few magnitude bins\n",
    "        let preview: Vec<f32> = magnitudes.iter().take(8).cloned().collect();\n",
    "        println!(\"Magnitude spectrum (first 8 bins): {:?}\", preview);\n",
    "        \n",
    "        // Find peak frequency\n",
    "        if let Some((peak_bin, &peak_mag)) = magnitudes.iter().enumerate().max_by(|a, b| a.1.partial_cmp(b.1).unwrap()) {\n",
    "            let peak_freq = peak_bin as f32 * freq_resolution;\n",
    "            println!(\"Peak at bin {} ({:.1} Hz) with magnitude {:.4}\", peak_bin, peak_freq, peak_mag);\n",
    "        }\n",
    "    }\n",
    "    Ok(())\n",
    "})();\n",
    "\n",
    "fft_res?;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba24941",
   "metadata": {},
   "source": [
    "## 6) Research extensions\n",
    "- Try multiple input channels (In>1) and probe cross-coupling via `C`.\n",
    "- Randomize or sweep parameterizations (e.g., vary damping and frequency bands).\n",
    "- Batch processing: increase `B` to process many sequences at once.\n",
    "- GPU: enable CUDA features in both Candle and the crate when needed.\n",
    "- For learning: integrate with Candle optimizers and loss functions (beyond scope here), treat layer params as trainable (they’re tensors)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "875ad1db",
   "metadata": {},
   "source": [
    "## 7) API quick reference for researchers\n",
    "\n",
    "Contract and shapes:\n",
    "- Input x: [B, T, In] (batch, time, input channels)\n",
    "- Output y: [B, T, Out]\n",
    "- Optional initial state w0: [B, 2m] where m = state_dim (concatenated position/velocity)\n",
    "- DType: f32 by default (set in config)\n",
    "- Device: CPU by default (set via Device::Cpu)\n",
    "\n",
    "Construction:\n",
    "- Create DLinOssLayerConfig { state_dim, input_dim, output_dim, delta_t, dtype }\n",
    "- Call DLinOssLayer::new(cfg, &device)\n",
    "\n",
    "Forward pass:\n",
    "- layer.forward(&x, None) or layer.forward(&x, Some(&w0))\n",
    "\n",
    "Stability and parameterization:\n",
    "- The implementation uses a damped IMEX-inspired discretization; stability hinges on non-negative damping G and clamping A into an admissible band.\n",
    "- For research sweeps, vary G (damping) and derived A within the band; monitor energy/RMS across longer T.\n",
    "\n",
    "What you can explore:\n",
    "- System ID: drive with impulse/step/sine sweeps; fit C,B (and A,G) via gradient-based learning using Candle optimizers.\n",
    "- Filtering/forecasting: provide streaming inputs and retain state (use the returned final state as next w0).\n",
    "- Multi-channel dynamics: set In>1/Out>1; probe cross-coupling via C and B.\n",
    "- Frequency locality: with fft feature, analyze band responses; tune damping per band.\n",
    "- Hardware: CPU by default; enable CUDA/Metal features in both Candle and this crate for GPU acceleration.\n",
    "\n",
    "Notes:\n",
    "- All parameters (A, G, B, C) are tensors and can be made trainable; integrate into a larger model graph with losses.\n",
    "- This notebook keeps things minimal and deterministic for clarity; extend with noise, nonlinearities, or stacked layers for richer models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97b8741f",
   "metadata": {},
   "source": [
    "## 8) Limitations and next steps\n",
    "- Streaming/online use would benefit from a `forward_with_state` API returning `(y, w_T)` to carry state across segments. Today `forward` returns only `y`; for streaming you can extend the crate to expose the final state.\n",
    "- Training: Wrap this layer in a larger Candle model, make `(a,g,b,c)` trainable, and connect to a task loss (e.g., forecasting MSE). Use standard optimizers (AdamW) and backprop through the scan.\n",
    "- Spectral tools: Enable the crate’s `fft` feature and re-export a simple real-FFT helper (via `dlinoss_augment::TensorFftExt`) to quantify band responses.\n",
    "- Multi-layer stacks: Stack D-LinOSS layers with residuals/MLPs to explore hierarchical oscillatory dynamics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f40cef6",
   "metadata": {},
   "source": [
    "## 9) Streaming/segmented processing\\nWhile the current `forward` method returns only the output sequence, you can manually simulate streaming by:\\n- Running small segments sequentially.\\n- Extracting the final internal state from one segment to initialize the next.\\n\\n**Note**: The current implementation doesn't expose the final state directly from `forward()`. For true streaming, you'd need to modify the crate to return `(output, final_state)` or add a `forward_with_state()` method. Below shows a manual approach by re-running with overlapping context.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bfec7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: [########################################] 100.0% | elapsed  30.0s\n",
      "Time budget reached (~30s). Stopping early at ~100.0%.\n",
      "\n",
      "Segmented processing complete: 4096 total output samples, RMS = 0.0000\n",
      "Note: For true streaming, extend the crate with forward_with_state() API\n"
     ]
    }
   ],
   "source": [
    "//! Doc: Manual streaming/segmented processing demonstration\n",
    "//! Tags: streaming, segments, overlap, manual-state, cell-streaming\n",
    "// Purpose: Show how to process long sequences in segments with overlap for pseudo-streaming.\n",
    "// Why: Demonstrates segmented processing when memory or latency constraints exist.\n",
    "// Approach: Use overlapping segments where the end of one provides context for the next, with a progress bar and time budget.\n",
    "// Limitation: True streaming needs forward_with_state() API; this is a workaround.\n",
    "// Performance: Overlap reduces efficiency but maintains causal dependencies.\n",
    "// Research: Useful for online processing or when sequence length exceeds memory limits.\n",
    "// Extensibility: Could be enhanced with proper state extraction from the layer.\n",
    "// Doc-scan: Header comments aid documentation tooling.\n",
    "// Signal generation: Use SignalGen::chirp method for long signal.\n",
    "//\n",
    "// What “streaming” means here:\n",
    "// - We process a long input in smaller chunks (segments). Each segment overlaps a bit with the previous one\n",
    "//   so dynamics have context across the boundary. This approximates online/real-time processing.\n",
    "// - Because DLinOssLayer::forward currently doesn’t return the final state, we restart from zero state\n",
    "//   for each segment. The overlap mitigates boundary artifacts but is not identical to true stateful streaming.\n",
    "//\n",
    "// Where outputs go:\n",
    "// - The output samples from each segment are collected into a local Vec<f32> named `all_outputs`.\n",
    "// - We skip the overlapping prefix on all but the first segment so we don’t double count samples.\n",
    "// - `all_outputs` is used to compute a final RMS and then dropped at the end of the closure. It’s not persisted.\n",
    "//   If you want to keep it, return it from the closure or write it to disk before returning.\n",
    "//\n",
    "// What to observe while it runs:\n",
    "// - A single-line progress bar that updates as segments are processed and shows elapsed seconds.\n",
    "// - If the time budget (~30s) is reached, the loop stops early with a message.\n",
    "// - At the end, you’ll see how many output samples were produced and their RMS value. The length may be\n",
    "//   slightly less than `total_length` if the final segment is shorter than the overlap (a benign truncation).\n",
    "//\n",
    "// About `stream_res?;` at the bottom:\n",
    "// - The closure returns a Result<()> that we bind to `stream_res`. The trailing `?` tells evcxr to surface any\n",
    "//   error nicely at the notebook level (it’s equivalent to `stream_res.unwrap()` but preserves error messages).\n",
    "// - On success, it’s effectively a no-op. It doesn’t “stream” to a destination; printing inside the closure is\n",
    "//   what you see in the cell output.\n",
    "\n",
    "let stream_res: Result<()> = (|| -> Result<()> {\n",
    "    use std::io::{self, Write};\n",
    "    use std::time::{Duration, Instant};\n",
    "    \n",
    "    let mut layer: DLinOssLayer = build_layer()?;\n",
    "    let total_length: usize = 4096usize; // keep reasonably sized for tutorial speed\n",
    "    let segment_size: usize = 512usize;  // larger segments -> fewer iterations\n",
    "    let overlap: usize = 64usize;        // small overlap for context\n",
    "    \n",
    "    // Time budget and progress bar settings\n",
    "    let start_time: Instant = Instant::now();\n",
    "    let max_duration: Duration = Duration::from_secs(30); // cap ~30s\n",
    "    let bar_width: usize = 40;\n",
    "    \n",
    "    // Generate a long chirp signal for segmented processing using SignalGen\n",
    "    let dt: f32 = layer.delta_t as f32;\n",
    "    let x_long: Tensor = SignalGen::chirp(total_length, 0.5, 10.0, dt)?;\n",
    "    let x_long_flat: Vec<f32> = x_long.squeeze(0)?.squeeze(1)?.to_vec1::<f32>()?;\n",
    "    \n",
    "    let mut all_outputs: Vec<f32> = Vec::with_capacity(total_length);\n",
    "    let mut start_idx: usize = 0;\n",
    "    \n",
    "    while start_idx < total_length {\n",
    "        let end_idx: usize = (start_idx + segment_size).min(total_length);\n",
    "        let segment_len: usize = end_idx - start_idx;\n",
    "        \n",
    "        // Extract segment from the long input (shape it back to [B=1, T=segment_len, In=1])\n",
    "        let segment_data: &[f32] = &x_long_flat[start_idx..end_idx];\n",
    "        let x_segment: Tensor = Tensor::from_slice(segment_data, (1, segment_len, 1), &Device::Cpu)?;\n",
    "        \n",
    "        // Process segment (no initial state - starts fresh each time)\n",
    "        // In a true streaming implementation, we’d pass the previous final state\n",
    "        let y_segment: Tensor = layer.forward(&x_segment, None)?;\n",
    "        let y_segment_flat: Vec<f32> = y_segment.squeeze(0)?.squeeze(1)?.to_vec1::<f32>()?;\n",
    "        \n",
    "        // Store output (skip overlap region except for first segment)\n",
    "        let store_start: usize = if start_idx == 0 { 0 } else { overlap };\n",
    "        all_outputs.extend_from_slice(&y_segment_flat[store_start..]);\n",
    "        \n",
    "        // Progress reporting: prints a single carriage-returned line that updates in-place\n",
    "        let processed: usize = end_idx;\n",
    "        let pct: f32 = (processed as f32 / total_length as f32) * 100.0;\n",
    "        let filled_len: usize = ((pct / 100.0) * bar_width as f32) as usize;\n",
    "        let mut bar: String = String::with_capacity(bar_width);\n",
    "        for _ in 0..filled_len { bar.push('#'); }\n",
    "        for _ in filled_len..bar_width { bar.push('-'); }\n",
    "        let elapsed: f32 = start_time.elapsed().as_secs_f32();\n",
    "        print!(\"\\rProgress: [{bar}] {pct:5.1}% | elapsed {elapsed:5.1}s\");\n",
    "        io::stdout().flush().ok();\n",
    "        \n",
    "        // Move to next segment with overlap (ensures continuity across boundaries)\n",
    "        start_idx = end_idx.saturating_sub(overlap);\n",
    "        \n",
    "        // Respect time budget\n",
    "        if start_time.elapsed() >= max_duration {\n",
    "            println!(\"\\nTime budget reached (~30s). Stopping early at ~{pct:.1}%.\");\n",
    "            break;\n",
    "        }\n",
    "    }\n",
    "    println!(); // newline after progress bar\n",
    "    \n",
    "    // Summarize output energy for a quick health check\n",
    "    let final_rms: f32 = {\n",
    "        let sum_sq: f32 = all_outputs.iter().map(|x| x * x).sum();\n",
    "        (sum_sq / all_outputs.len() as f32).sqrt()\n",
    "    };\n",
    "    \n",
    "    println!(\"Segmented processing complete: {} total output samples, RMS = {:.4}\", \n",
    "             all_outputs.len(), final_rms);\n",
    "    println!(\"Note: For true streaming, extend the crate with forward_with_state() API\");\n",
    "    Ok(())\n",
    "})();\n",
    "\n",
    "// Surface any error from the closure at the notebook level; no-op on success\n",
    "stream_res?;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Rust",
   "language": "rust",
   "name": "rust"
  },
  "language_info": {
   "codemirror_mode": "rust",
   "file_extension": ".rs",
   "mimetype": "text/rust",
   "name": "rust",
   "pygment_lexer": "rust",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
